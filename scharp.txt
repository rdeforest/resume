DataFax is the data management software used by the SCHARP organization within Fred Hutch Cancer Research Center. SCHARP stands for Statistical Center for HIV and AIDS Research and Prevention. The data in question was study participant data used by data scientists and primary investigators to execute clinical trials for medications and methods. For an example of a study which was a major part of my responsibilities, see https://www.mtnstopshiv.org/research/studies/mtn-003

In these studies, project managers directed clinical sites to sign up participants and meet with them regularly as directed under the approved protocol for that study. Depending on what was being tested, participants might take a medication, try to change a behavior, or both, and the site would take their vitals and observations when the participant came in. The data from those meetings went onto forms which the sites sent to SCHARP via FAX and email-FAX. The DataFax software was programmed to perform Optical Character Recognition on the forms, which were designed to limit errors. The Data Operations Group (referred to as DOGs) would validate and correct the invested forms, and the safety group would reach out to sites if any of the data exceeded limits which might indicate that participants might be at risk, either from participation or even other unrelated causes. Data scientists wrote automation to pull this corrected data from out of DataFax to then analyze to determine the results of the study.

My role in all this was to keep DataFax running securely, correctly, and with sufficient performance to not slow down the DOGs. In support of that, I was responsible for updates, monitoring, troubleshooting and coming up with ways to prepare for future changes and unexpected events.

When the DataFax company released a version 4 of their software, I was entirely responsible for figuring out how to move the studies from version 3 without any changes that would negatively impact their protocol conformance. To do that, I wrote a library in the DataFax scripting language which bridge the modules using the old API to the new API. The only changes required were to change each study's library to use my bridge. Explicitly requiring the studies to switch over was how I ensured that it was easy to tell whether a study had been upgraded. My library made it so that the arguments to the funciton calls didn't change, only the names. The typical edited lines per study was around five: one to include my library and four to change the names of the called functions. This made validation fast and simple.

The new version also provided an Internet-facing service to expose features to sites, which constituted a new attack surface. Our security specialist was adamant that under no circumstances would he sign off on opening ports for this. I wrote a five page paper which changed his mind by breaking down exactly what the exposure was, all the worst case scenarios, the costs of breaches (both in terms of money and more importantly, safety), and how the software and I were mitigating all those risks. The paper changed his mind.

The monitoring systems I inherited, and indeed all the automation outside of DataFax itself, were all written in Perl, which I already had extensive experience with. One such script was 7000 lines, of which at least half was long rambling comments written by someone who was sleep deprived (or so he told me). When I joined, the script had stopped working a few weeks prior, and my first task was both to fix it and also process the backlog. The script monitored incoming study data and sent reports out to sites so they could verify that we received and processed the same number of forms as they sent. I updated the script, did a code review with my manager and processed the backlog in my first week.

We didn't have many issues to troubleshoot. Occasionally sites had problems with their faxes which I diagnosed based on what came through on our end, and also on the noises I heard on the line while talking with them. Line noise was a big problem, especially in older cities. However, we did have one storage failure which caused DataFax to misbehave. As soon as I got a report from a user of what they were seeing I called up the infrastructure team, and they explained they had just turned quota monitoring on. Knowing how DataFax works, I had a good idea of how badly it would fail under these conditions, so I stopped the service, sent an announcement to users and other stakeholders, and contacted the vendor to confirm my assumptions and ask for alternative suggestions. They said my assumptions were correct and the remediation I proposed (rolling back to a snapshot from before quota monitoring) was the only safe option. I then contacted the head of the DOGs and she looped in a project manager to drive resolution. I fully documented my plan and why it was the best option and then presented it to the board the next morning for their approval. There were no questions, so after that I went back to my office and worked all day with the project manager and DOGs manager to validate the rolled-back studies and document the event for each of the studies so that they remained within data integrity guarantee requirements.

At SCHARP I learned a great deal about working within strict requirements, writing good documentation, handling surprises, working with people who have different styles, making changes as small and clear as possible, testing, and integrating diverse software (DataFax, SAS, Perl scripts, Java programs).
